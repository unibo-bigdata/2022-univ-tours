{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dd7243a-b7d3-4e47-b3ec-49cafdebada5",
   "metadata": {},
   "source": [
    "# 201 Spark basics\n",
    "\n",
    "The goal of this package is to get familiar with Spark programming.\n",
    "\n",
    "- [Spark programming guide](https://spark.apache.org/docs/latest/rdd-programming-guide.html)\n",
    "- [PySpark RDD APIs](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05b8fdd-ef59-4e64-b749-1d9ae50260bc",
   "metadata": {},
   "source": [
    "## 201-5 Spark warm-up\n",
    "\n",
    "Load the ```riddle``` dataset and try the following actions:\n",
    "- Show its content (```collect```)\n",
    "- Count the rows (```count```)\n",
    "- Split phrases into words (```map``` or ```flatMap```; whatâ€™s the difference?)\n",
    "- Check the results (remember: evaluation is lazy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3897182a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucketname = \"univ-tours-bd2223-egallinucci\"\n",
    "\n",
    "rddRiddle = sc.textFile(\"s3a://\"+bucketname+\"/datasets/riddle.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ab59be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rddRiddle.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b77f0b5-2a9c-4cf6-919e-74e146acbbdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rddRiddle.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141a1ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rddRiddle.map(lambda row: row.split(\" \") ).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d695aad-b99e-455b-b116-3526971ee0f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rddRiddle.flatMap(lambda row: row.split(\" \") ).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2d9363-3ce0-411b-a826-ee3cceb935a1",
   "metadata": {},
   "source": [
    "## 201-6 Spark jobs\n",
    "\n",
    "Implement some basic Spark jobs. Try first on the ```riddle``` dataset, then execute on the ```fiction``` one.\n",
    "\n",
    "- Jobs:\n",
    "  - Count the number of occurrences of each word\n",
    "    - Result: ('si', 1), ('ton', 2), ('tonton', 3), ...\n",
    "  - Count the number of occurrences of words of given lengths\n",
    "    - Result: (2, 1), (3, 3), ...\n",
    "  - Count the average length of words given their first letter (hint: check the slides for aggregating multiple values)\n",
    "    - Result: ('s', 3.0), ('m', 3.0), ('t', 4.7)\n",
    "  - Return the inverted index of words (hints: use the ```zipWithIndex``` method; to print an key-value RDD with a list in the value, use ```mapValues(list)```)\n",
    "    - Result: ('si', \\[0]), ('ton', \\[0, 1]), ...\n",
    "\n",
    "- How is the output sorted? How can you sort by value?\n",
    "- Try the ```toDebugString``` function to check the execution plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbe5dcd-5e6b-4837-bccc-1f83bca44761",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rddRiddle = sc.textFile(\"s3a://\"+bucketname+\"/datasets/riddle.txt\")\n",
    "rddFiction = sc.textFile(\"s3a://\"+bucketname+\"/datasets/fiction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6e0992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "myRdd = rddRiddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d39ced5-45b9-4f7b-a679-6897e76f31ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Word count\n",
    "\n",
    "rddWordCount = myRdd.\\\n",
    "    flatMap(lambda row: row.split(\" \") ).\\\n",
    "    map(lambda word: (word,1)).\\\n",
    "    reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "rddWordCount.take(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e141737a-283d-412e-97f6-a53004180a75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Word length count\n",
    "\n",
    "rddWLC = myRdd.\\\n",
    "    flatMap(lambda row: row.split(\" \") ).\\\n",
    "    map(lambda word: (len(word),1)).\\\n",
    "    reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "rddWLC.take(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab4132f-114c-4d97-acc6-a2d53730a0d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Average word length by initial\n",
    "\n",
    "rddWLBA = myRdd.\\\n",
    "    flatMap(lambda row: row.split(\" \") ).\\\n",
    "    filter(lambda word: len(word)>0).\\\n",
    "    map(lambda word: (word[0:1].lower(), (len(word), 1))).\\\n",
    "    reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1])).\\\n",
    "    mapValues(lambda v: v[0]/v[1])\n",
    "\n",
    "rddWLBA.take(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a0f9e3-6bcf-4018-b6b1-ae1ef0a61ccf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inverted index (word-based offset)\n",
    "\n",
    "rddII = myRdd.\\\n",
    "    flatMap(lambda row: row.split(\" \")).\\\n",
    "    filter(lambda word: len(word)>0).\\\n",
    "    zipWithIndex().\\\n",
    "    groupByKey().\\\n",
    "    mapValues(list)\n",
    "\n",
    "rddII.take(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080be4bd-c8d1-4908-90a5-06df1f165a2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inverted index (sentence-based offset)\n",
    "\n",
    "rddII2 = myRdd.\\\n",
    "    zipWithIndex().\\\n",
    "    map(lambda el: (el[1], el[0])).\\\n",
    "    flatMapValues(lambda row: row.split(\" \")).\\\n",
    "    filter(lambda el: len(el[1])>0).\\\n",
    "    map(lambda el: (el[1], el[0])).\\\n",
    "    distinct().\\\n",
    "    groupByKey().\\\n",
    "    mapValues(list)\n",
    "\n",
    "rddII2.take(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f934ef2c-6956-442a-b869-93f65425bda4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sort an RDD by key\n",
    "\n",
    "rddWordCount.sortByKey().collect()\n",
    "\n",
    "# Sort an RDD by value\n",
    "\n",
    "rddWordCount.map(lambda el: (el[1], el[0])).sortByKey().collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
